{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9dathS_lkMu"
      },
      "source": [
        "# Learning and practicing NumPy with examples and exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ejercicios**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Third element: 1\n",
            "Sliced array (index 1 to 3): [7 1 9]\n",
            "Array after changing the fourth element: [ 3  7  1 12  5]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos el array de numpy\n",
        "arr = np.array([3, 7, 1, 9, 5])\n",
        "\n",
        "# a) Recuperar el tercer elemento de la matriz\n",
        "third_element = arr[2]\n",
        "print(\"Third element:\", third_element)\n",
        "\n",
        "# b) Corta la matriz para obtener los elementos del índice 1 al índice 3\n",
        "sliced_array = arr[1:4]\n",
        "print(\"Sliced array (index 1 to 3):\", sliced_array)\n",
        "\n",
        "# c) Cambia el valor del cuarto elemento a 12\n",
        "arr[3] = 12\n",
        "print(\"Array after changing the fourth element:\", arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elemento en la fila 2, columna 3: 6\n",
            "Submatriz (primeras dos filas): [[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ],
      "source": [
        "# Definimos la matriz\n",
        "matrix = np.array([\n",
        "            [1, 2, 3],\n",
        "            [4, 5, 6],  \n",
        "            [7, 8, 9]\n",
        "        ])\n",
        "\n",
        "# a) Recuperamos el elemento en la fila 2, columna 3\n",
        "elemento = matrix[1, 2]\n",
        "print(\"Elemento en la fila 2, columna 3:\", elemento)\n",
        "\n",
        "# b) Corta la matriz para obtener la submatriz formada por las dos primeras filas y todas las columnas.\n",
        "submatrix = matrix[:2, :]\n",
        "print(\"Submatriz (primeras dos filas):\", submatrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elemento en la posición (1, 0, 2): 15\n",
            "Sub-tensor 3×4 (segunda matriz):\n",
            " [[13 14 15 16]\n",
            " [17 18 19 20]\n",
            " [21 22 23 24]]\n",
            "Sub-tensor 2×4 (última fila de las dos últimas matrices):\n",
            " [[21 22 23 24]\n",
            " [33 34 35 36]]\n",
            "Elemento en la posición (2, 1, 3): 32\n",
            "Sub-tensor 2×4 (primera fila de las dos últimas matrices):\n",
            " [[13 14 15 16]\n",
            " [25 26 27 28]]\n"
          ]
        }
      ],
      "source": [
        "# Definimos el tensor 3D\n",
        "tensor = np.array([\n",
        "    [\n",
        "        [1, 2, 3, 4],\n",
        "        [5, 6, 7, 8],\n",
        "        [9, 10, 11, 12]\n",
        "    ],\n",
        "    [\n",
        "        [13, 14, 15, 16],\n",
        "        [17, 18, 19, 20],\n",
        "        [21, 22, 23, 24]\n",
        "    ],\n",
        "    [\n",
        "        [25, 26, 27, 28],\n",
        "        [29, 30, 31, 32],\n",
        "        [33, 34, 35, 36]\n",
        "    ]\n",
        "])\n",
        "\n",
        "# 1. Recuperar el elemento en la posición (1, 0, 2)\n",
        "element_1 = tensor[1, 0, 2]\n",
        "print(\"Elemento en la posición (1, 0, 2):\", element_1)\n",
        "\n",
        "# 2. Cortar el tensor para obtener el sub-tensor 3×4 que corresponde a la segunda \"matriz\" (corte) a lo largo de la primera dimensión\n",
        "sub_tensor = tensor[1, :, :]\n",
        "print(\"Sub-tensor 3×4 (segunda matriz):\\n\", sub_tensor)\n",
        "\n",
        "# 3. Cortar el tensor para obtener el sub-tensor 2×4 que corresponde a la última fila de las dos últimas \"matrices.\"\n",
        "last_row_last_two_matrices = tensor[1:, 2, :]\n",
        "print(\"Sub-tensor 2×4 (última fila de las dos últimas matrices):\\n\", last_row_last_two_matrices)\n",
        "\n",
        "# 4. Recuperar el elemento en la posición (2, 1, 3)\n",
        "element_2 = tensor[2, 1, 3]\n",
        "print(\"Elemento en la posición (2, 1, 3):\", element_2)\n",
        "\n",
        "# 5. Cortar el tensor para obtener el sub-tensor 2×4 que corresponde a la primera fila de las dos últimas \"matrices.\"\n",
        "first_row_last_two_matrices = tensor[1:, 0, :]\n",
        "print(\"Sub-tensor 2×4 (primera fila de las dos últimas matrices):\\n\", first_row_last_two_matrices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18.0\n"
          ]
        }
      ],
      "source": [
        "def calculate_average(numbers):\n",
        "    if not numbers:  # Evita división por cero si la lista está vacía\n",
        "        return 0\n",
        "    return sum(numbers) / len(numbers)\n",
        "\n",
        "# Ejemplo de uso:\n",
        "nums = [4, 8, 15, 16, 23, 42]\n",
        "print(calculate_average(nums))  # Resultado: 18.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "def find_power(base, exponente):\n",
        "    return base ** exponente\n",
        "\n",
        "b, e = 2, 3\n",
        "resultado = find_power(b, e)  # Resultado: 8\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Theta final: [[0.69871031]\n",
            " [2.50035722]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Datos\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([3, 6, 8, 11, 13])\n",
        "\n",
        "# Visualizar los datos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', marker='o', label='Datos originales')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Datos para regresión lineal')\n",
        "plt.grid(True)\n",
        "\n",
        "# Normalizar los datos para un mejor rendimiento del descenso de gradiente\n",
        "# En este caso simple no es necesario, pero es una buena práctica\n",
        "X_norm = (X - np.mean(X)) / np.std(X)\n",
        "\n",
        "# Parámetros\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "\n",
        "# Inicializar los parámetros theta\n",
        "theta = np.zeros(2)  # [theta_0, theta_1]\n",
        "\n",
        "# Historial para visualizar la convergencia\n",
        "J_history = np.zeros(num_iterations)\n",
        "\n",
        "# Número de ejemplos\n",
        "m = len(X)\n",
        "\n",
        "# Añadir columna de unos para theta_0\n",
        "X_b = np.c_[np.ones((m, 1)), X_norm]\n",
        "\n",
        "# Función de costo\n",
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    predictions = X.dot(theta)\n",
        "    cost = (1/(2*m)) * np.sum(np.square(predictions - y))\n",
        "    return cost\n",
        "\n",
        "# Función de descenso de gradiente\n",
        "def gradient_descent(X, y, theta, alpha, iterations):\n",
        "    m = len(y)\n",
        "    theta_history = np.zeros((iterations, 2))\n",
        "    \n",
        "    for i in range(iterations):\n",
        "        # Calcular las predicciones con los valores actuales de theta\n",
        "        predictions = X.dot(theta)\n",
        "        \n",
        "        # Calcular errores\n",
        "        errors = predictions - y\n",
        "        \n",
        "        # Calcular gradientes\n",
        "        gradients = (1/m) * X.T.dot(errors)\n",
        "        \n",
        "        # Actualizar theta\n",
        "        theta = theta - alpha * gradients\n",
        "        \n",
        "        # Guardar historia de theta y costo\n",
        "        theta_history[i, :] = theta\n",
        "        J_history[i] = compute_cost(X, y, theta)\n",
        "        \n",
        "    return theta, J_history, theta_history\n",
        "\n",
        "# Ejecutar descenso de gradiente\n",
        "theta, J_history, theta_history = gradient_descent(X_b, y, theta, learning_rate, num_iterations)\n",
        "\n",
        "# Desnormalizar theta para obtener parámetros para los datos originales\n",
        "# theta_0 = theta[0] - theta[1] * mean(X) / std(X)\n",
        "# theta_1 = theta[1] / std(X)\n",
        "theta_0_original = theta[0] - theta[1] * np.mean(X) / np.std(X)\n",
        "theta_1_original = theta[1] / np.std(X)\n",
        "\n",
        "print(\"Theta encontrados después de la normalización:\", theta)\n",
        "print(\"Theta desnormalizados:\")\n",
        "print(f\"theta_0 = {theta_0_original}\")\n",
        "print(f\"theta_1 = {theta_1_original}\")\n",
        "\n",
        "# Evaluar el modelo\n",
        "# Ecuación de la recta: y = theta_0 + theta_1 * x\n",
        "print(f\"Ecuación de la recta: y = {theta_0_original:.4f} + {theta_1_original:.4f} * x\")\n",
        "\n",
        "# Calcular R-cuadrado\n",
        "y_pred = theta_0_original + theta_1_original * X\n",
        "ss_total = np.sum((y - np.mean(y))**2)\n",
        "ss_residual = np.sum((y - y_pred)**2)\n",
        "r_squared = 1 - (ss_residual / ss_total)\n",
        "print(f\"R-cuadrado: {r_squared:.4f}\")\n",
        "\n",
        "# Visualizar la convergencia del costo\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(num_iterations), J_history)\n",
        "plt.xlabel('Iteraciones')\n",
        "plt.ylabel('Costo J')\n",
        "plt.title('Convergencia del descenso de gradiente')\n",
        "plt.grid(True)\n",
        "\n",
        "# Visualizar la línea de regresión\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', marker='o', label='Datos originales')\n",
        "plt.plot(X, y_pred, color='red', label='Línea de regresión')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Regresión Lineal con Descenso de Gradiente')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Calcular predicciones para algunos valores\n",
        "x_test = np.array([0, 6])\n",
        "y_test = theta_0_original + theta_1_original * x_test\n",
        "print(f\"Predicciones: Para x=0: {y_test[0]:.2f}, Para x=6: {y_test[1]:.2f}\")\n",
        "\n",
        "# Mostrar todo\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "redes310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
